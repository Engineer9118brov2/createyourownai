# ğŸ¤– AI Assistant Builder

A no-code AI assistant builder prototype with **local Ollama support** and **cloud API integration** (Claude, ChatGPT, Grok). Built with Streamlit for a simple, intuitive interface.

## âœ¨ Features

- **ğŸ  Home Dashboard**: Connection status, available backends, usage analytics, quick test
- **âœ¨ Create Assistants**: Multi-field form with system prompts and knowledge base (RAG)
- **ğŸ‘¥ Manage Assistants**: Create, edit, delete, export/import assistants as JSON
- **ğŸ’¬ Multi-Backend Chat**: Switch between Ollama (local), Claude, ChatGPT, or Grok
- **ğŸ“š Knowledge Base (RAG)**: Upload PDF/TXT files to give assistants context
- **ğŸ¨ Theme Support**: Dark/Light mode toggle
- **ğŸ‘¤ User Profiles**: Per-user assistant storage
- **ğŸ”‘ API Key Management**: Secure session-based storage for API keys
- **ğŸ“Š Usage Analytics**: Track actions and usage patterns
- **ğŸš€ Deployment Helpers**: Docker, Streamlit Cloud, Heroku, AWS EC2 snippets
- **âš™ï¸ Model Management**: Pull, list, delete Ollama models from UI

## ğŸ› ï¸ Tech Stack

- **Frontend**: Streamlit 1.28+
- **Local AI**: Ollama
- **Cloud APIs**: Anthropic Claude, OpenAI ChatGPT, xAI Grok
- **Data**: JSON files (per-user), PyPDF2 for document extraction
- **Python**: 3.10+

## ğŸ“¦ Quick Installation

```bash
# Clone and setup
git clone https://github.com/Engineer9118brov2/createyourownai.git
cd createyourownai
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Setup environment (optional)
cp .env.template .env

# Install Ollama (optional, for local models)
# macOS: brew install ollama
# Linux: curl https://ollama.ai/install.sh | sh
# Windows: Download from https://ollama.ai

# Start Ollama (in separate terminal)
ollama serve

# Pull a model
ollama pull llama3

# Run the app
streamlit run app.py
```

Access at `http://localhost:8501`

## ğŸš€ Quick Start

1. **Settings** âš™ï¸ â†’ Set username, add API keys (optional)
2. **Create Assistant** âœ¨ â†’ Name, description, system prompt
3. **Test Chat** ğŸ’¬ â†’ Select assistant & backend, chat!
4. **My Assistants** ğŸ‘¥ â†’ Export, import, manage assistants

## ğŸ“„ Files

- `app.py` - Main Streamlit app with all pages
- `ai_helper.py` - Unified backend interface (Ollama, Claude, ChatGPT, Grok)
- `pages/settings.py` - Settings, API keys, model management, analytics
- `assistants.json` - Default (empty) assistants file
- `requirements.txt` - Python dependencies
- `.env.template` - Environment variables template

## ğŸ”‘ API Keys (Optional)

All API keys are stored in-memory (session state only) - never written to disk!

- **Claude**: [console.anthropic.com](https://console.anthropic.com)
- **ChatGPT**: [platform.openai.com](https://platform.openai.com)
- **Grok**: [console.x.ai](https://console.x.ai)

## ğŸ³ Docker

```bash
docker build -t ai-assistant-builder .
docker run -p 8501:8501 ai-assistant-builder
```

## ğŸ“Š Troubleshooting

**Ollama not connecting?**
```bash
curl http://localhost:11434/api/tags
ollama serve
```

**No models?**
```bash
ollama pull llama3
```

**API key issues?**
- Verify key is correct in Settings
- Check service credentials are active
- Clear session and re-enter

## ğŸ“ Features in Detail

### Home
- Dashboard with connection status
- Quick test any backend
- Quick-start tutorial

### Create Assistant
- Name, description, system prompt
- Optional knowledge base (PDF/TXT)
- Status (Active/Draft)

### My Assistants
- View all assistants
- Export as JSON
- Import from JSON
- Delete assistants

### Test Chat
- Select assistant & backend
- Full message history
- Copy message button
- Export chat as JSON

### Settings
- User profile & theme
- API key management
- Ollama model management
- Deployment guides
- Usage analytics
- Session management

## ğŸ“„ License

MIT License

---

**Need help?** Check the [Streamlit docs](https://docs.streamlit.io) or open an issue!
